{{ template "chart.header" . }}
{{ template "chart.deprecationWarning" . }}

{{ template "chart.badgesSection" . }}

{{ template "chart.description" . }}

{{ template "chart.homepageLine" . }}

{{ template "chart.maintainersSection" . }}

{{ template "chart.sourcesSection" . }}

## Prerequisites

### API Key and Secrets Management

Create a [WhyLabs API Key](https://docs.whylabs.ai/docs/whylabs-api/#creating-an-api-token)
that will be used when creating the required Kubernetes secrets to authenticate
with the WhyLabs API.

You can manage the API keys and container secrets in one of two ways, depending on your preferred setup: 

1. **Kubernetes Secret-based Management (default)**

    In this setup, secrets are passed as environment variables by creating Kubernetes Secrets manually. The following commands show how to create secrets for the API key and container authentication:

    Use the following `kubectl` commands to create the required Kubernetes
    `Secrets`. These secrets must exist prior to installing the Helm chart.

    ```shell
    # API that was created above
    whylabs_api_key=""
    # Arbitrary value that will be required to make requests to the containers
    container_password=""
    # Change this to the desired namespace
    target_namespace="default"
    # Helm release name (See installation for release_name usage)
    release_name=""

    kubectl create secret generic "whylabs-${release_name}-api-key" \
      --namespace "${target_namespace}" \
      --from-literal=WHYLABS_API_KEY="${whylabs_api_key}"

    kubectl create secret generic "whylabs-${release_name}-api-secret" \
      --namespace "${target_namespace}" \
      --from-literal=CONTAINER_PASSWORD="${container_password}"

    kubectl create secret docker-registry "whylabs-${release_name}-registry-credentials" \
      --namespace "${target_namespace}" \
      --docker-server="registry.gitlab.com" \
      --docker-username="<whylabs-provided-username>" \
      --docker-password="<whylabs-provided-token>" \
      --docker-email="<whylabs-provided-email>"
    ```

2. **File-based Secrets Management with CSI Drivers**

    If you prefer to use file-based secrets with tools like the AWS Secrets Store CSI Driver, you can configure the Helm chart to load secrets from files mounted into the container. To use file-based secrets, set envFrom: {} in your values.yaml file to disable the environment variable-based configuration.

    Example configuration for file-based secrets:

    - Modify the envFrom section in your `values.yaml`:

        ```yaml
        envFrom: {}
        ```
    - Use your CSI driver to mount secrets as files into the container, which allows
    the application to read the secrets directly from the filesystem.

### Choose Your Secret Management Strategy

- Environment Variables: This is the default method and requires you to populate secrets as Kubernetes environment variables. Leave the envFrom section in values.yaml unchanged or configure it with your Kubernetes secret references:

    ```yaml
    envFrom:
      whylabs-guardrails-api-key:
        type: secretRef
        optional: true
      whylabs-guardrails-api-secret:
        type: secretRef
        optional: true
    ```

- File-based Secrets: If you are using a CSI driver, set envFrom: {} in your
values.yaml and ensure your secrets are available as mounted files.

## Installation & Upgrades

> :warning: To expose guardrails to callers outside of your K8s cluster you will
need an Ingress Controller such as
[NGINX Ingress Controller](https://kubernetes.github.io/ingress-nginx/), a
Gateway Controller such as [Ambassador](https://www.getambassador.io/), a
Service Mesh such as [Istio](https://istio.io/), or a Load Balancer Controller
such as [AWS Load Balancer Controller](https://kubernetes-sigs.github.io/aws-load-balancer-controller).
The installation and configuration of the aforementioned controllers are outside
the scope of this document. However, for a quickstart guide to expose Guardrails
to the public internet via AWS LBC, see the
[Exposing Guardrails Outside Kubernetes](#exposing-guardrails-outside-kubernetes)
section.

### How to Use WhyLabs Helm Repository

> :warning: WhyLab's Helm charts are hosted on GitHub Container Registry (GHCR),
> an OCI-compliant storage solution. GHCR aligns with industry standards for
> container artifact storage and has a slightly different API to be aware of.
> Use the `helm pull` command to download the a `.tgz` archive of the chart.
> Reference the `.tgz` archive as the chart identifier when installing.

```shell
# Specify the namespace to install the chart into
target_namespace=""
# Helm release name
release_name=""

# The following command will download a guardrails-${chart_version}.tgz file to
# the working directory or --destination path
helm pull \
  oci://ghcr.io/whylabs/{{ template "chart.name" . }} \
  --version {{ template "chart.version" . }}

# Requires the helm-diff plugin to be installed:
# helm plugin install https://github.com/databus23/helm-diff
helm diff upgrade \
  --allow-unreleased \
  --namespace "${target_namespace}" \
  "${release_name}" {{ template "chart.name" . }}-{{ template "chart.version" . }}.tgz
```

After you've installed the repo you can install the chart.

```shell
helm upgrade --install \
  --create-namespace \
  --namespace "${target_namespace}" \
  "${release_name}" {{ template "chart.name" . }}-{{ template "chart.version" . }}.tgz
```

## Exposing Guardrails Outside Kubernetes

This section serves as a quickstart guide to install AWS LBC and configure the
Helm chart to expose Guardrails outside of your Kubernetes cluster via an
internal NLB.

1. [Install AWS LBC](https://kubernetes-sigs.github.io/aws-load-balancer-controller/latest/deploy/installation/)
1. Modify the `values.yaml` file:
    1. Change `service.type` to `LoadBalancer`
    1. Set `service.annotations` to the appropriate annotations for your desired
  load balancer configuration. 

The following `values.yaml` service configuration will create a Network
Load Balancer (NLB) that resolves to private IP addresses and registers the Pod
IPs as load balancer targets:

```yaml
service:
  annotations:
    # Explicitly delegate LB controll to AWS Load Balancer Controller
    service.beta.kubernetes.io/aws-load-balancer-type: "external"
    # Create an NLB that resolves to public IP addresses
    service.beta.kubernetes.io/aws-load-balancer-scheme: "internal"
    # Register the Pods IPs as load balancer targets
    service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: "ip"
    # Use TCP protocol for traffic between NLB and Pods
    service.beta.kubernetes.io/aws-load-balancer-backend-protocol: "tcp"
  # Must be of type LoadBalancer
  type: LoadBalancer
```

## Horizontal Pod Autoscaling (HPA)

The Horizontal Pod Autoscaler automatically scales the number of pods in a
replication controller, deployment, replica set or stateful set based on
observed CPU utilization (or, with custom metrics support, on some other
application-provided metrics). The Horizontal Pod Autoscaler uses the following
formula to calculate the desired number of pods:

```text
Desired Replicas = [ (Current Utilization / Target Utilization) * Current Replicas ]
```

For example, if an HPA is configured with a target CPU utilization of 50%, there
are currently 3 pods, and the current average CPU utilization is 90%, the number
of replicas will be scaled to 6:

```text
Desired Replicas = ⌈ (90% / 50%) * 3 ⌉
                 = ⌈ 1.8 * 3 ⌉
                 = ⌈ 5.4 ⌉
                 = 6
```

HPA uses the same formula for both increasing and decreasing the number of pods.
Horizontal pod scaling is disabled by default. To enable it, set the
`hpa.enabled` key to `true`. The pods QoS class will impact HPA behavior as a
deployment that is allowed to burst CPU usage will cause more aggressive HPA
scaling than a deployment with a `Guaranteed` QoS that does not go above 100%
utilization.

{{ template "chart.requirementsSection" . }}

{{ template "chart.valuesSection" . }}

----------------------------------------------

Autogenerated from chart metadata using [helm-docs](https://github.com/norwoodj/helm-docs/).